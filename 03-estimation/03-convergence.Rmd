---
title: "Convergence checks"
date: "`r format(Sys.time(), '%d %B %Y, %H:%M')`"
output:
  html_notebook:
    code_folding: hide
    toc: yes
    toc_float: yes
---
<style type="text/css"> <!-- .table { width: auto } ---> </style>

```{r options, include=FALSE}
knitr::opts_chunk$set(
  # results = "hide",
  message = FALSE,
  warning = FALSE,
  package.startup.message = FALSE
  )

options(
  knitr.kable.NA = "",
  width = 100
)
```

```{r}
suppressMessages(library(rstan))

wp_model <- 2  # set Model to estimate -- M1 or M2

file_wikipedia <- "../01-data-sources/02-wikipedia/wikipedia-data/01-wp-data-json.zip"
file_wikipedia_date <- substr(file.info(file_wikipedia)$mtime, 1, 10)

file_estimation <- list.files(
  "../03-estimation/estimation-model", 
  pattern = sprintf("02-stan-samples-m%d_[[:digit:]].csv", wp_model),
  full.names = TRUE
)
file_estimation_date <- substr(file.info(file_estimation)$mtime, 1, 10)
```

__Model `r wp_model`__ â€” M1 ideology tags only, M2 ideology and position tags

+ Wikipedia data download -- `r file_wikipedia_date`
+ Model estimation -- `r file_estimation_date`
+ [ date file modified ]


## Convergence diagnosis
```{r}
stan_out <- read_stan_csv(file_estimation)
```

```{r}
params <- setNames(c("a", "b", "o", "x"), nm = c("alpha", "beta", "o", "x"))

if (wp_model == 2) {
  
  params <- c(setNames(c("g", "t"), nm = c("gamma", "tau")), params)
  
}

pl_params <- substr(params, 1, 1)
n_params <- length(params)

posterior_stats <- summary(stan_out, pars = params)$summary
samples <- extract(stan_out, pars = params)
```

```{r}
get_df <- function(var) {

  rows_param <- lapply(
    params,
    function(.x) grep(
      paste0(.x, "($|\\[[[:digit:]]*\\]$)"), 
      rownames(posterior_stats)
    )
  )
  param_stat <- sapply(rows_param, function(.x) posterior_stats[.x, var])

  quantile_select <- c(0.99, 0.95, 0.9, 0.75, 0.5)
  digits <- 3
  
  if (var == "n_eff") {
    
    quantile_select <- abs(quantile_select - 1)
    digits <- 0
    
  }

  dt <- data.frame(
    maxmin = round(sapply(param_stat, max), digits),
    quant = t(round(sapply(param_stat, quantile, quantile_select), digits)),
    mean = round(sapply(param_stat, mean), digits),
    N_par = sapply(param_stat, length)
  )
  if (var == "n_eff") {
    
    dt$maxmin <- round(sapply(param_stat, min), digits)

  }
  
  names(dt) <- gsub("maxmin", ifelse(var == "n_eff", "min", "max"), names(dt))
  names(dt) <- gsub("quant\\.", "", names(dt))
  names(dt) <- gsub("\\.$", "%", names(dt))
  rownames(dt) <- names(params)
  
  return(dt)
}
```

Scale reduction factors $\hat{R}$ --- close to one and all values < 1.05.

```{r}
get_df("Rhat")
```

Effective samples sizes $N_{eff}$ --- all values > 100

```{r}
get_df("n_eff")
```


## SD / Mean checks

Confirming $\bar{x} = 0$

```{r}
round(mean(samples$x), 3)
```

Confirming $\text{SD}(x) = 1$

```{r}
round(sd(samples$x), 3)
```


## Distribution parties

```{r}
plot(density(apply(samples$x, 2, mean)), main = "")
```


## Traceplots

Inspect traceplots for particular parameters

__Plots only presented for critical values__

-----

```{r}
check_condition <- function(var_1, operator, var_2) {
  
   operator(var_1, var_2)
  
}

get_plots <- function(var, operator, value) {
  
  select <- which(check_condition(posterior_stats[, var], operator, value))
  pars <- rownames(posterior_stats[select, ])

  if (! is.null(pars)) {
    
    traceplot(stan_out, pars = pars)

  }
  
}
```

### R-hat

Parameters with $\hat{R} > 1.05$

```{r}
get_plots("Rhat", `>`, 1.05)
```

### N-eff

Parameters with $N_{eff} < 100$

```{r}
get_plots("n_eff", `<`, 100)
```
